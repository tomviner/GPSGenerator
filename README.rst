GPS tracking simulation for a Carrier-Workers coordination Company
==========================================================

Introduction
-----------------
This a small simulator for generating gps coordinates, simulating a fleet of carriers or workers within a big city.

Objective
-------------
The main objective for this script is to have a flexible, easy to use and customizable stream of gps corrdinates.

Motivation
---------------
I need this tool for testing database storing of a big stream of gps tracking.
This is for personal use. I am considering transforming this repo in a small library agnostic to databases and personal data structures.

Proof of concept
------------------
Why store raw gps tracks inline if we can process them with some structure?
Structure de data first!  this is the main goal. it will allow us to gain two very important goals.:

> **Release-the-database:**  With the purpose of not hitting the database for writing, even if there is a write only master (postgres)  lets design something that will scale, from the beginning.
The intention of this is to save in a redis server de data flow generated by the carriers. Similar to a buffer. And collect them in a bulk process (worker , for example celery) when the metrics says its better in a scheduled task.

> **Storing some structured data in memory(redis):**  This, will allow us also to have some realtime, observable state. ( ok realtime is an illusion in networked architectures like this ) That means we can query the redis about active deliveries, visualize them in a frontend(map)  and track the real situation and location of the carriers. Without hitting the database.

**possible disadvantages**

-  Delaying disk writes in the database could be tricky,  doing it in a bulk process can cause an overhead in disk writes. It is necessary to schedule this process, in many small steps. Doing this in small hours could recomendable. Its possible that already exist a redis-potgresql syncing solution  or using redis as a cache layer for postgres. .. (I need further study)
·· Interesting link: https://github.com/pg-redis-fdw/redis_fdw

-  Redis itself. Storing a big dataflow in redis could be dangerous. If the server dies. or there is a network problem, we can have issues, with data integrity. Master-slave replication, with a falldown detection could be the solution.



Implementation specifics
--------------------------


Why not TDD
-------------------
Ok, i thought that i will use python generator, coroutines, and a scheduler since  the begining and because I really did not  know how deep this rabbithole will be. I decided not to do tdd this time. This script is a test itself. I will rebuild this script with tests, when i really know how to do it.

Performance Issues
--------------------------- 
I wanted a small memory footprint script, thats why i decided to do it with generators, at first sight, memory use seems to be ok. but with an intensive use of the script, the cpu is not stable. ( in this toy macbook air )
I will check cpu issues.

Speed Issues
------------------
This script generates the stream, I decided to implemente this generator and scheduler trick, to simulate some concurrency, and have fine control of the simulation, in one thread. That' s why this goes slow.

